{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.ipynb_checkpoints', 'assets', 'pictures', 'project_group_IOT.ipynb', 'README.md']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"./assets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-c9fb36673f9e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-c9fb36673f9e>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    kaggle datasets download -d iabhishekofficial/mobile-price-classification\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'kaggle' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = \"mapraw1997@outlook.com\" # username from the json file\n",
    "os.environ['KAGGLE_KEY'] = \"583006Kaggle\" # key from the json file\n",
    "!kaggle datasets download -d iabhishekofficial/mobile-price-classification # api copied from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
      "0   1           1043     1          1.8         1  14       0           5   \n",
      "\n",
      "   m_dep  mobile_wt  ...  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
      "0    0.1        193  ...  16        226      1412  3476    12     7   \n",
      "\n",
      "   talk_time  three_g  touch_screen  wifi  \n",
      "0          2        0             1     0  \n",
      "\n",
      "[1 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "print(test.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
      "0            842     0          2.2         0   1       0           7    0.6   \n",
      "\n",
      "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
      "0        188        2  ...         20       756  2549     9     7         19   \n",
      "\n",
      "   three_g  touch_screen  wifi  price_range  \n",
      "0        0             0     1            1  \n",
      "\n",
      "[1 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "print(train.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc',\n",
      "       'four_g', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc',\n",
      "       'px_height', 'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
      "       'touch_screen', 'wifi'],\n",
      "      dtype='object')\n",
      "Index(['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
      "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
      "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
      "       'touch_screen', 'wifi', 'price_range'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(test.columns)\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id'}\n",
      "{'price_range'}\n",
      "count    2000.000000\n",
      "mean        1.500000\n",
      "std         1.118314\n",
      "min         0.000000\n",
      "25%         0.750000\n",
      "50%         1.500000\n",
      "75%         2.250000\n",
      "max         3.000000\n",
      "Name: price_range, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(set(test.columns)-set(train.columns))\n",
    "print(set(train.columns)-set(test.columns))\n",
    "print(train[\"price_range\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 ... 3 0 3]\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "train_price_y = np.array(train[\"price_range\"])\n",
    "print((train_price_y))\n",
    "data = train_price_y\n",
    "shape = (data.size, data.max()+1)\n",
    "one_hot_y = np.zeros(shape)\n",
    "rows = np.arange(data.size)\n",
    "one_hot_y[rows, data] = 1\n",
    "print(one_hot_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test.drop(columns=[\"id\"])\n",
    "train_x = train.drop(columns=[\"price_range\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train in the wrong way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 1.4091 - accuracy: 0.2550\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.3591 - accuracy: 0.2502\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.3201 - accuracy: 0.2478\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2936 - accuracy: 0.2490\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2708 - accuracy: 0.3638\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2595 - accuracy: 0.4245\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2181 - accuracy: 0.4750\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1953 - accuracy: 0.4694\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1733 - accuracy: 0.4897\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1778 - accuracy: 0.4418\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1604 - accuracy: 0.5162\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1479 - accuracy: 0.5187\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1376 - accuracy: 0.5003\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1261 - accuracy: 0.4935\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1124 - accuracy: 0.5153\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1142 - accuracy: 0.4787\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1245 - accuracy: 0.4898\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0884 - accuracy: 0.5114\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1141 - accuracy: 0.4671\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0853 - accuracy: 0.5022\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0777 - accuracy: 0.4979\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0730 - accuracy: 0.4917\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0532 - accuracy: 0.5271\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0646 - accuracy: 0.5310\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0381 - accuracy: 0.5336\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0736 - accuracy: 0.5087\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0585 - accuracy: 0.5369\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0138 - accuracy: 0.5669\n",
      "Epoch 29/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0414 - accuracy: 0.5296\n",
      "Epoch 30/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0148 - accuracy: 0.5383\n",
      "Epoch 31/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0154 - accuracy: 0.5376\n",
      "Epoch 32/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9996 - accuracy: 0.5649\n",
      "Epoch 33/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9966 - accuracy: 0.5547\n",
      "Epoch 34/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9945 - accuracy: 0.5214\n",
      "Epoch 35/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9941 - accuracy: 0.5644\n",
      "Epoch 36/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0065 - accuracy: 0.5317\n",
      "Epoch 37/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9984 - accuracy: 0.5241\n",
      "Epoch 38/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9894 - accuracy: 0.5604\n",
      "Epoch 39/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9450 - accuracy: 0.5523\n",
      "Epoch 40/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9588 - accuracy: 0.5939\n",
      "Epoch 41/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9496 - accuracy: 0.5887\n",
      "Epoch 42/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9346 - accuracy: 0.6008\n",
      "Epoch 43/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9447 - accuracy: 0.5780\n",
      "Epoch 44/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9322 - accuracy: 0.6208\n",
      "Epoch 45/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9425 - accuracy: 0.5755\n",
      "Epoch 46/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9493 - accuracy: 0.5729\n",
      "Epoch 47/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9092 - accuracy: 0.5837\n",
      "Epoch 48/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9170 - accuracy: 0.5680\n",
      "Epoch 49/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9057 - accuracy: 0.5979\n",
      "Epoch 50/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9091 - accuracy: 0.6030\n",
      "Epoch 51/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9473 - accuracy: 0.5652\n",
      "Epoch 52/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9119 - accuracy: 0.5915\n",
      "Epoch 53/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8987 - accuracy: 0.5946\n",
      "Epoch 54/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8815 - accuracy: 0.6178\n",
      "Epoch 55/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8917 - accuracy: 0.6110\n",
      "Epoch 56/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8705 - accuracy: 0.5978\n",
      "Epoch 57/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8519 - accuracy: 0.6225\n",
      "Epoch 58/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8685 - accuracy: 0.6315\n",
      "Epoch 59/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8815 - accuracy: 0.6245\n",
      "Epoch 60/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8928 - accuracy: 0.5986\n",
      "Epoch 61/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8913 - accuracy: 0.6096\n",
      "Epoch 62/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9002 - accuracy: 0.6021\n",
      "Epoch 63/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8459 - accuracy: 0.6320\n",
      "Epoch 64/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8778 - accuracy: 0.6135\n",
      "Epoch 65/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8254 - accuracy: 0.6576\n",
      "Epoch 66/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8353 - accuracy: 0.6543\n",
      "Epoch 67/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8240 - accuracy: 0.6716\n",
      "Epoch 68/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8343 - accuracy: 0.6410\n",
      "Epoch 69/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8062 - accuracy: 0.6527\n",
      "Epoch 70/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8005 - accuracy: 0.6859\n",
      "Epoch 71/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8177 - accuracy: 0.6462\n",
      "Epoch 72/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8280 - accuracy: 0.6563\n",
      "Epoch 73/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8340 - accuracy: 0.6320\n",
      "Epoch 74/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8213 - accuracy: 0.6630\n",
      "Epoch 75/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8103 - accuracy: 0.6493\n",
      "Epoch 76/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8259 - accuracy: 0.6522\n",
      "Epoch 77/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8209 - accuracy: 0.6263\n",
      "Epoch 78/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8166 - accuracy: 0.6280\n",
      "Epoch 79/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8317 - accuracy: 0.6260\n",
      "Epoch 80/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8140 - accuracy: 0.6431\n",
      "Epoch 81/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7998 - accuracy: 0.6584\n",
      "Epoch 82/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7770 - accuracy: 0.6663\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7898 - accuracy: 0.6651\n",
      "Epoch 84/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8145 - accuracy: 0.6488\n",
      "Epoch 85/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7930 - accuracy: 0.6669\n",
      "Epoch 86/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7924 - accuracy: 0.6727\n",
      "Epoch 87/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7932 - accuracy: 0.6569\n",
      "Epoch 88/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8099 - accuracy: 0.6244\n",
      "Epoch 89/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8286 - accuracy: 0.6428\n",
      "Epoch 90/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8020 - accuracy: 0.6578\n",
      "Epoch 91/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8386 - accuracy: 0.6251\n",
      "Epoch 92/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8335 - accuracy: 0.6200\n",
      "Epoch 93/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7851 - accuracy: 0.6428\n",
      "Epoch 94/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8071 - accuracy: 0.6215\n",
      "Epoch 95/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8063 - accuracy: 0.5997\n",
      "Epoch 96/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7934 - accuracy: 0.6117\n",
      "Epoch 97/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7974 - accuracy: 0.6549\n",
      "Epoch 98/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7908 - accuracy: 0.6519\n",
      "Epoch 99/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8080 - accuracy: 0.6422\n",
      "Epoch 100/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8084 - accuracy: 0.6602\n",
      "Epoch 101/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7847 - accuracy: 0.6508\n",
      "Epoch 102/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8261 - accuracy: 0.6205\n",
      "Epoch 103/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7502 - accuracy: 0.6667\n",
      "Epoch 104/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7737 - accuracy: 0.6637\n",
      "Epoch 105/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7865 - accuracy: 0.6665\n",
      "Epoch 106/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7668 - accuracy: 0.6603\n",
      "Epoch 107/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7510 - accuracy: 0.6879\n",
      "Epoch 108/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7935 - accuracy: 0.6379\n",
      "Epoch 109/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7680 - accuracy: 0.6461\n",
      "Epoch 110/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7852 - accuracy: 0.6504\n",
      "Epoch 111/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7828 - accuracy: 0.6455\n",
      "Epoch 112/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7738 - accuracy: 0.6671\n",
      "Epoch 113/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7827 - accuracy: 0.6542\n",
      "Epoch 114/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7578 - accuracy: 0.6679\n",
      "Epoch 115/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7681 - accuracy: 0.6504\n",
      "Epoch 116/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7700 - accuracy: 0.6575\n",
      "Epoch 117/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7812 - accuracy: 0.6689\n",
      "Epoch 118/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7630 - accuracy: 0.6775\n",
      "Epoch 119/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7596 - accuracy: 0.6708\n",
      "Epoch 120/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7277 - accuracy: 0.6884\n",
      "Epoch 121/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8127 - accuracy: 0.6303\n",
      "Epoch 122/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7518 - accuracy: 0.6771\n",
      "Epoch 123/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7391 - accuracy: 0.6752\n",
      "Epoch 124/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7419 - accuracy: 0.6847\n",
      "Epoch 125/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7537 - accuracy: 0.6698\n",
      "Epoch 126/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7475 - accuracy: 0.6763\n",
      "Epoch 127/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7801 - accuracy: 0.6574\n",
      "Epoch 128/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7776 - accuracy: 0.6633\n",
      "Epoch 129/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7192 - accuracy: 0.7056\n",
      "Epoch 130/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7346 - accuracy: 0.6847\n",
      "Epoch 131/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7490 - accuracy: 0.6575\n",
      "Epoch 132/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7685 - accuracy: 0.6704\n",
      "Epoch 133/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7540 - accuracy: 0.6596\n",
      "Epoch 134/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7678 - accuracy: 0.6528\n",
      "Epoch 135/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7576 - accuracy: 0.6628\n",
      "Epoch 136/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7318 - accuracy: 0.6892\n",
      "Epoch 137/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7271 - accuracy: 0.6799\n",
      "Epoch 138/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7502 - accuracy: 0.6752\n",
      "Epoch 139/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7706 - accuracy: 0.6526\n",
      "Epoch 140/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7403 - accuracy: 0.6905\n",
      "Epoch 141/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7853 - accuracy: 0.6572\n",
      "Epoch 142/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7142 - accuracy: 0.7130\n",
      "Epoch 143/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7444 - accuracy: 0.6705\n",
      "Epoch 144/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7221 - accuracy: 0.7041\n",
      "Epoch 145/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7923 - accuracy: 0.6230\n",
      "Epoch 146/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7512 - accuracy: 0.6463\n",
      "Epoch 147/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7292 - accuracy: 0.6615\n",
      "Epoch 148/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7864 - accuracy: 0.6197\n",
      "Epoch 149/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7639 - accuracy: 0.6517\n",
      "Epoch 150/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7340 - accuracy: 0.6788\n",
      "Epoch 151/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7965 - accuracy: 0.6635\n",
      "Epoch 152/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7779 - accuracy: 0.6463\n",
      "Epoch 153/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7676 - accuracy: 0.6681\n",
      "Epoch 154/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7416 - accuracy: 0.6774\n",
      "Epoch 155/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7318 - accuracy: 0.6717\n",
      "Epoch 156/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7185 - accuracy: 0.6839\n",
      "Epoch 157/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7549 - accuracy: 0.6630\n",
      "Epoch 158/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7391 - accuracy: 0.6799\n",
      "Epoch 159/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7377 - accuracy: 0.6904\n",
      "Epoch 160/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7388 - accuracy: 0.7010\n",
      "Epoch 161/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7643 - accuracy: 0.6533\n",
      "Epoch 162/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7317 - accuracy: 0.6867\n",
      "Epoch 163/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7330 - accuracy: 0.6871\n",
      "Epoch 164/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7685 - accuracy: 0.6809\n",
      "Epoch 165/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7607 - accuracy: 0.6588\n",
      "Epoch 166/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7451 - accuracy: 0.6826\n",
      "Epoch 167/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7151 - accuracy: 0.6895\n",
      "Epoch 168/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 0.6960\n",
      "Epoch 169/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.7001\n",
      "Epoch 170/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7352 - accuracy: 0.6937\n",
      "Epoch 171/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8020 - accuracy: 0.6500\n",
      "Epoch 172/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7251 - accuracy: 0.6813\n",
      "Epoch 173/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7437 - accuracy: 0.6805\n",
      "Epoch 174/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9483 - accuracy: 0.5671\n",
      "Epoch 175/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8613 - accuracy: 0.6623\n",
      "Epoch 176/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7429 - accuracy: 0.6838\n",
      "Epoch 177/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7369 - accuracy: 0.6785\n",
      "Epoch 178/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.7081\n",
      "Epoch 179/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7300 - accuracy: 0.6865\n",
      "Epoch 180/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.7283\n",
      "Epoch 181/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7506 - accuracy: 0.6778\n",
      "Epoch 182/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7384 - accuracy: 0.7004\n",
      "Epoch 183/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7220 - accuracy: 0.6891\n",
      "Epoch 184/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7490 - accuracy: 0.6739\n",
      "Epoch 185/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7687 - accuracy: 0.6404\n",
      "Epoch 186/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7045 - accuracy: 0.6885\n",
      "Epoch 187/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7360 - accuracy: 0.6784\n",
      "Epoch 188/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7855 - accuracy: 0.6638\n",
      "Epoch 189/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7520 - accuracy: 0.6854\n",
      "Epoch 190/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7323 - accuracy: 0.6699\n",
      "Epoch 191/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7709 - accuracy: 0.6638\n",
      "Epoch 192/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7762 - accuracy: 0.6580\n",
      "Epoch 193/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7426 - accuracy: 0.6775\n",
      "Epoch 194/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.7120\n",
      "Epoch 195/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7155 - accuracy: 0.6844\n",
      "Epoch 196/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7429 - accuracy: 0.6774\n",
      "Epoch 197/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7096 - accuracy: 0.6894\n",
      "Epoch 198/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7407 - accuracy: 0.6625\n",
      "Epoch 199/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7131 - accuracy: 0.6862\n",
      "Epoch 200/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7315 - accuracy: 0.6932\n",
      "Epoch 201/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7139 - accuracy: 0.6984\n",
      "Epoch 202/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7168 - accuracy: 0.6938\n",
      "Epoch 203/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8287 - accuracy: 0.6186\n",
      "Epoch 204/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7350 - accuracy: 0.6893\n",
      "Epoch 205/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7412 - accuracy: 0.6735\n",
      "Epoch 206/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7352 - accuracy: 0.6651\n",
      "Epoch 207/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7112 - accuracy: 0.6854\n",
      "Epoch 208/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7297 - accuracy: 0.6946\n",
      "Epoch 209/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7544 - accuracy: 0.6531\n",
      "Epoch 210/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7261 - accuracy: 0.6882\n",
      "Epoch 211/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7389 - accuracy: 0.6726\n",
      "Epoch 212/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7489 - accuracy: 0.6583\n",
      "Epoch 213/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7315 - accuracy: 0.6714\n",
      "Epoch 214/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6985 - accuracy: 0.7034\n",
      "Epoch 215/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8215 - accuracy: 0.6335\n",
      "Epoch 216/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7254 - accuracy: 0.6890\n",
      "Epoch 217/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7271 - accuracy: 0.6795\n",
      "Epoch 218/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7119 - accuracy: 0.6904\n",
      "Epoch 219/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.6916\n",
      "Epoch 220/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7028 - accuracy: 0.6896\n",
      "Epoch 221/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7167 - accuracy: 0.6767\n",
      "Epoch 222/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7478 - accuracy: 0.6895\n",
      "Epoch 223/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7582 - accuracy: 0.6323\n",
      "Epoch 224/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7262 - accuracy: 0.6762\n",
      "Epoch 225/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7397 - accuracy: 0.6603\n",
      "Epoch 226/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7183 - accuracy: 0.6843\n",
      "Epoch 227/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7572 - accuracy: 0.6598\n",
      "Epoch 228/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7971 - accuracy: 0.6470\n",
      "Epoch 229/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7488 - accuracy: 0.6780\n",
      "Epoch 230/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7171 - accuracy: 0.6781\n",
      "Epoch 231/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7231 - accuracy: 0.6990\n",
      "Epoch 232/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7181 - accuracy: 0.6826\n",
      "Epoch 233/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7639 - accuracy: 0.6263\n",
      "Epoch 234/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7328 - accuracy: 0.6867\n",
      "Epoch 235/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.7059\n",
      "Epoch 236/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6992 - accuracy: 0.7000\n",
      "Epoch 237/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.6717\n",
      "Epoch 238/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7209 - accuracy: 0.6775\n",
      "Epoch 239/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7030 - accuracy: 0.6930\n",
      "Epoch 240/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7057 - accuracy: 0.6975\n",
      "Epoch 241/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7433 - accuracy: 0.6932\n",
      "Epoch 242/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7096 - accuracy: 0.6854\n",
      "Epoch 243/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7539 - accuracy: 0.6794\n",
      "Epoch 244/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7244 - accuracy: 0.6982\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7053 - accuracy: 0.7137\n",
      "Epoch 246/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8401 - accuracy: 0.6256\n",
      "Epoch 247/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7634 - accuracy: 0.6541\n",
      "Epoch 248/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.6912\n",
      "Epoch 249/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7274 - accuracy: 0.6803\n",
      "Epoch 250/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7146 - accuracy: 0.6911\n",
      "Epoch 251/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7327 - accuracy: 0.6781\n",
      "Epoch 252/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7285 - accuracy: 0.6744\n",
      "Epoch 253/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7747 - accuracy: 0.6077\n",
      "Epoch 254/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7336 - accuracy: 0.6439\n",
      "Epoch 255/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7506 - accuracy: 0.6809\n",
      "Epoch 256/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7486 - accuracy: 0.6526\n",
      "Epoch 257/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7206 - accuracy: 0.6718\n",
      "Epoch 258/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7185 - accuracy: 0.6870\n",
      "Epoch 259/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7078 - accuracy: 0.6843\n",
      "Epoch 260/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7319 - accuracy: 0.6605\n",
      "Epoch 261/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7612 - accuracy: 0.6662\n",
      "Epoch 262/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6985 - accuracy: 0.6866\n",
      "Epoch 263/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7074 - accuracy: 0.6873\n",
      "Epoch 264/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.6837\n",
      "Epoch 265/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7159 - accuracy: 0.6804\n",
      "Epoch 266/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7249 - accuracy: 0.6725\n",
      "Epoch 267/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7193 - accuracy: 0.6898\n",
      "Epoch 268/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7028 - accuracy: 0.7029\n",
      "Epoch 269/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7075 - accuracy: 0.6975\n",
      "Epoch 270/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7036 - accuracy: 0.6782\n",
      "Epoch 271/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7217 - accuracy: 0.6908\n",
      "Epoch 272/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7614 - accuracy: 0.6495\n",
      "Epoch 273/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7394 - accuracy: 0.6492\n",
      "Epoch 274/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.6942\n",
      "Epoch 275/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7205 - accuracy: 0.6789\n",
      "Epoch 276/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7131 - accuracy: 0.6897\n",
      "Epoch 277/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7276 - accuracy: 0.6800\n",
      "Epoch 278/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.6875\n",
      "Epoch 279/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7487 - accuracy: 0.6839\n",
      "Epoch 280/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.6901\n",
      "Epoch 281/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7266 - accuracy: 0.6724\n",
      "Epoch 282/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.6935\n",
      "Epoch 283/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7186 - accuracy: 0.6772\n",
      "Epoch 284/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7464 - accuracy: 0.6365\n",
      "Epoch 285/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7400 - accuracy: 0.6871\n",
      "Epoch 286/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.6674\n",
      "Epoch 287/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7563 - accuracy: 0.6277\n",
      "Epoch 288/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7228 - accuracy: 0.6940\n",
      "Epoch 289/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.6880\n",
      "Epoch 290/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7350 - accuracy: 0.6914\n",
      "Epoch 291/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.6996\n",
      "Epoch 292/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6652 - accuracy: 0.7317\n",
      "Epoch 293/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7202 - accuracy: 0.6961\n",
      "Epoch 294/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7051 - accuracy: 0.7174\n",
      "Epoch 295/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7313 - accuracy: 0.6976\n",
      "Epoch 296/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.7118\n",
      "Epoch 297/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.7136\n",
      "Epoch 298/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.7159\n",
      "Epoch 299/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7421 - accuracy: 0.6995\n",
      "Epoch 300/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7185 - accuracy: 0.7039\n",
      "Epoch 301/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7229 - accuracy: 0.7040\n",
      "Epoch 302/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.7165\n",
      "Epoch 303/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7754 - accuracy: 0.6771\n",
      "Epoch 304/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7400 - accuracy: 0.6771\n",
      "Epoch 305/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7181 - accuracy: 0.6959\n",
      "Epoch 306/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7098 - accuracy: 0.6923\n",
      "Epoch 307/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.6979\n",
      "Epoch 308/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7088 - accuracy: 0.6960\n",
      "Epoch 309/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6771 - accuracy: 0.7264\n",
      "Epoch 310/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6990 - accuracy: 0.7080\n",
      "Epoch 311/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6998 - accuracy: 0.7143\n",
      "Epoch 312/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7000 - accuracy: 0.7075\n",
      "Epoch 313/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8082 - accuracy: 0.6481\n",
      "Epoch 314/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.7084\n",
      "Epoch 315/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6722 - accuracy: 0.7172\n",
      "Epoch 316/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.7111\n",
      "Epoch 317/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.7157\n",
      "Epoch 318/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6752 - accuracy: 0.7180\n",
      "Epoch 319/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6549 - accuracy: 0.7322\n",
      "Epoch 320/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7070 - accuracy: 0.6983\n",
      "Epoch 321/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.6866\n",
      "Epoch 322/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.7120\n",
      "Epoch 323/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6759 - accuracy: 0.7050\n",
      "Epoch 324/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.7092\n",
      "Epoch 325/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6743 - accuracy: 0.7158\n",
      "Epoch 326/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.7053\n",
      "Epoch 327/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.6877\n",
      "Epoch 328/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6734 - accuracy: 0.7196\n",
      "Epoch 329/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 0.6986\n",
      "Epoch 330/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.7029\n",
      "Epoch 331/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7605 - accuracy: 0.6700\n",
      "Epoch 332/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.7116\n",
      "Epoch 333/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.6940\n",
      "Epoch 334/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7115 - accuracy: 0.6995\n",
      "Epoch 335/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.6955\n",
      "Epoch 336/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7434 - accuracy: 0.6728\n",
      "Epoch 337/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.7241\n",
      "Epoch 338/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.7163\n",
      "Epoch 339/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.7261\n",
      "Epoch 340/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.7119\n",
      "Epoch 341/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.7364\n",
      "Epoch 342/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.7213\n",
      "Epoch 343/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7041 - accuracy: 0.7068\n",
      "Epoch 344/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 0.7165\n",
      "Epoch 345/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7118 - accuracy: 0.6958\n",
      "Epoch 346/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7326 - accuracy: 0.7033\n",
      "Epoch 347/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7204 - accuracy: 0.6892\n",
      "Epoch 348/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7509 - accuracy: 0.7129\n",
      "Epoch 349/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.7099\n",
      "Epoch 350/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.7080\n",
      "Epoch 351/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7164 - accuracy: 0.6781\n",
      "Epoch 352/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.6991\n",
      "Epoch 353/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.7186\n",
      "Epoch 354/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.7042\n",
      "Epoch 355/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6753 - accuracy: 0.7279\n",
      "Epoch 356/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.7223\n",
      "Epoch 357/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6653 - accuracy: 0.7294\n",
      "Epoch 358/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6702 - accuracy: 0.7226\n",
      "Epoch 359/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6676 - accuracy: 0.7205\n",
      "Epoch 360/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.7092\n",
      "Epoch 361/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.7088\n",
      "Epoch 362/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6397 - accuracy: 0.7383\n",
      "Epoch 363/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7943 - accuracy: 0.6122\n",
      "Epoch 364/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7151 - accuracy: 0.6954\n",
      "Epoch 365/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7110 - accuracy: 0.6855\n",
      "Epoch 366/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6627 - accuracy: 0.7363\n",
      "Epoch 367/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.7152\n",
      "Epoch 368/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.7179\n",
      "Epoch 369/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7132 - accuracy: 0.6872\n",
      "Epoch 370/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6590 - accuracy: 0.7242\n",
      "Epoch 371/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.6813\n",
      "Epoch 372/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7071 - accuracy: 0.6911\n",
      "Epoch 373/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.6962\n",
      "Epoch 374/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7151 - accuracy: 0.6993\n",
      "Epoch 375/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.7033\n",
      "Epoch 376/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6657 - accuracy: 0.7113\n",
      "Epoch 377/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6610 - accuracy: 0.7320\n",
      "Epoch 378/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6621 - accuracy: 0.7213\n",
      "Epoch 379/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.7087\n",
      "Epoch 380/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.7188\n",
      "Epoch 381/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7578 - accuracy: 0.6708\n",
      "Epoch 382/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.7229\n",
      "Epoch 383/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7253 - accuracy: 0.6877\n",
      "Epoch 384/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6743 - accuracy: 0.7161\n",
      "Epoch 385/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.7060\n",
      "Epoch 386/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6722 - accuracy: 0.7228\n",
      "Epoch 387/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.7076\n",
      "Epoch 388/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6766 - accuracy: 0.7293\n",
      "Epoch 389/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.7216\n",
      "Epoch 390/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7250 - accuracy: 0.6909\n",
      "Epoch 391/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.7211\n",
      "Epoch 392/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6558 - accuracy: 0.7239\n",
      "Epoch 393/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.7261\n",
      "Epoch 394/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6971 - accuracy: 0.7061\n",
      "Epoch 395/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.7130\n",
      "Epoch 396/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.7268\n",
      "Epoch 397/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7137 - accuracy: 0.6803\n",
      "Epoch 398/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.7069\n",
      "Epoch 399/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6688 - accuracy: 0.7358\n",
      "Epoch 400/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7456 - accuracy: 0.6558\n",
      "Epoch 401/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7020 - accuracy: 0.6963\n",
      "Epoch 402/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.7110\n",
      "Epoch 403/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6688 - accuracy: 0.7261\n",
      "Epoch 404/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6657 - accuracy: 0.7297\n",
      "Epoch 405/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6628 - accuracy: 0.7211\n",
      "Epoch 406/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.7132\n",
      "Epoch 407/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.7030\n",
      "Epoch 408/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.7290\n",
      "Epoch 409/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6716 - accuracy: 0.7157\n",
      "Epoch 410/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.7307\n",
      "Epoch 411/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.6991\n",
      "Epoch 412/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.7395\n",
      "Epoch 413/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.7337\n",
      "Epoch 414/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7082 - accuracy: 0.6999\n",
      "Epoch 415/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.7235\n",
      "Epoch 416/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.7106\n",
      "Epoch 417/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7073 - accuracy: 0.6951\n",
      "Epoch 418/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.7175\n",
      "Epoch 419/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.7266\n",
      "Epoch 420/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6979 - accuracy: 0.7082\n",
      "Epoch 421/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6649 - accuracy: 0.7209\n",
      "Epoch 422/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.7150\n",
      "Epoch 423/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6789 - accuracy: 0.7150\n",
      "Epoch 424/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7283 - accuracy: 0.7075\n",
      "Epoch 425/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.7323\n",
      "Epoch 426/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.7350\n",
      "Epoch 427/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.7261\n",
      "Epoch 428/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.7236\n",
      "Epoch 429/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7661 - accuracy: 0.6287\n",
      "Epoch 430/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6731 - accuracy: 0.7381\n",
      "Epoch 431/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.7005\n",
      "Epoch 432/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7104 - accuracy: 0.6744\n",
      "Epoch 433/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.6990\n",
      "Epoch 434/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.7293\n",
      "Epoch 435/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7154 - accuracy: 0.6929\n",
      "Epoch 436/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7151 - accuracy: 0.6448\n",
      "Epoch 437/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.7261\n",
      "Epoch 438/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6745 - accuracy: 0.7078\n",
      "Epoch 439/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7049 - accuracy: 0.7040\n",
      "Epoch 440/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.7134\n",
      "Epoch 441/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.6945\n",
      "Epoch 442/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.7214\n",
      "Epoch 443/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7473 - accuracy: 0.6283\n",
      "Epoch 444/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7275 - accuracy: 0.6379\n",
      "Epoch 445/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.7034\n",
      "Epoch 446/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.7037\n",
      "Epoch 447/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7134 - accuracy: 0.6827\n",
      "Epoch 448/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.6729\n",
      "Epoch 449/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7133 - accuracy: 0.6423\n",
      "Epoch 450/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7108 - accuracy: 0.6743\n",
      "Epoch 451/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.6449\n",
      "Epoch 452/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 0.6933\n",
      "Epoch 453/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.7146\n",
      "Epoch 454/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.6659\n",
      "Epoch 455/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.6843\n",
      "Epoch 456/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7056 - accuracy: 0.7038\n",
      "Epoch 457/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6703 - accuracy: 0.7147\n",
      "Epoch 458/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.6786\n",
      "Epoch 459/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6722 - accuracy: 0.6787\n",
      "Epoch 460/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6720 - accuracy: 0.7180\n",
      "Epoch 461/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6798 - accuracy: 0.7089\n",
      "Epoch 462/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.7011\n",
      "Epoch 463/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.7294\n",
      "Epoch 464/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.7361\n",
      "Epoch 465/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.7346\n",
      "Epoch 466/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6390 - accuracy: 0.7468\n",
      "Epoch 467/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.7155\n",
      "Epoch 468/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.7065\n",
      "Epoch 469/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.7262\n",
      "Epoch 470/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.7193\n",
      "Epoch 471/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.7241\n",
      "Epoch 472/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6454 - accuracy: 0.7380\n",
      "Epoch 473/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6742 - accuracy: 0.7175\n",
      "Epoch 474/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7138 - accuracy: 0.6951\n",
      "Epoch 475/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7037 - accuracy: 0.7056\n",
      "Epoch 476/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6707 - accuracy: 0.7247\n",
      "Epoch 477/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6778 - accuracy: 0.7226\n",
      "Epoch 478/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6753 - accuracy: 0.7233\n",
      "Epoch 479/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6390 - accuracy: 0.7490\n",
      "Epoch 480/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6294 - accuracy: 0.7416\n",
      "Epoch 481/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6759 - accuracy: 0.7171\n",
      "Epoch 482/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6414 - accuracy: 0.7455\n",
      "Epoch 483/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.7205\n",
      "Epoch 484/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6733 - accuracy: 0.7303\n",
      "Epoch 485/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.7282\n",
      "Epoch 486/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.7248\n",
      "Epoch 487/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.7041\n",
      "Epoch 488/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6720 - accuracy: 0.7178\n",
      "Epoch 489/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6796 - accuracy: 0.7307\n",
      "Epoch 490/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.7484\n",
      "Epoch 491/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6314 - accuracy: 0.7481\n",
      "Epoch 492/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.7063\n",
      "Epoch 493/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.7203\n",
      "Epoch 494/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6432 - accuracy: 0.7390\n",
      "Epoch 495/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6421 - accuracy: 0.7323\n",
      "Epoch 496/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.7333\n",
      "Epoch 497/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6632 - accuracy: 0.7303\n",
      "Epoch 498/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.7341\n",
      "Epoch 499/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6628 - accuracy: 0.7328\n",
      "Epoch 500/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6641 - accuracy: 0.7182\n"
     ]
    }
   ],
   "source": [
    "# NN\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(len(train_x.columns), input_dim=len(train_x.columns), activation='relu'))\n",
    "model.add(Dense(len(train_x.columns)/2, input_dim=len(train_x.columns), activation='sigmoid'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(train_x, one_hot_y, epochs=500, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_predict = model.predict(train_x)\n",
    "# a = accuracy_score(pred,test)\n",
    "# print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.944"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(train_x,train_price_y)\n",
    "\n",
    "#cheat\n",
    "y_model = model.predict(train_x)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(train_price_y, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Train in the right way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x1,x2,y1,y2 = train_test_split(train_x,train_price_y, random_state=64, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=50)\n",
    "model.fit(x1,y1)\n",
    "\n",
    "#predict\n",
    "y_model = model.predict(x2)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y2, y_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93   0.9425 0.92   0.93   0.905 ]\n",
      "0.928\n"
     ]
    }
   ],
   "source": [
    "X = train_x\n",
    "y = train_price_y\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(model, X,y,cv=5))\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "scores = cross_val_score(model, X,y,cv=LeaveOneOut().split(X))\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=7, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\"n_neighbors\":np.arange(1,100)}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=7)\n",
    "grid.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 12}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "model = grid.best_estimator_\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = model.fit(x1,y1).predict(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9266666666666666"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(train_x,train_price_y, random_state=64, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 0:00:06.023258\n"
     ]
    }
   ],
   "source": [
    "C = 1 #@param {type:\"slider\", min:1.0, max:3.0, step:0.1}\n",
    "kernel = \"linear\" #@param ['linear', 'poly', 'rbf']\n",
    "gamma = \"scale\"  #@param ['scale', 'auto']\n",
    "\n",
    "svm = SVC(\n",
    "  C=C,\n",
    "  kernel=kernel,\n",
    "  gamma=gamma,\n",
    "  cache_size=4096,\n",
    "   random_state=0\n",
    ")\n",
    "\n",
    "svm_start_time = time.time()\n",
    "model=svm.fit(X_train,y_train)\n",
    "svm_end_time = time.time()\n",
    "print(f\"Training Time: {datetime.timedelta(seconds=svm_end_time-svm_start_time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9683333333333334"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict\n",
    "y_model = model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy = 0.5342857142857143\n",
      "Test set accuracy = 0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mapraw\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Linear SVC version\n",
    "# Create a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "clf_linSVC = Pipeline([\n",
    "    (\"linear_svc\", LinearSVC(C=200, loss=\"hinge\", max_iter=100000))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "clf_linSVC.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "print(\"Train set accuracy = \" + str(clf_linSVC.score(X_train, y_train)))\n",
    "print(\"Test set accuracy = \" + str(clf_linSVC.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy = 1.0\n",
      "Test set accuracy = 0.23833333333333334\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Gaussian RBF Kernel version\n",
    "# Create a pipeline\n",
    "clf_SVC = Pipeline([\n",
    "    (\"linear_svc\", SVC(kernel=\"rbf\", gamma=2, C=10, max_iter=10000))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "clf_SVC.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "print(\"Train set accuracy = \" + str(clf_SVC.score(X_train, y_train)))\n",
    "print(\"Test set accuracy = \" + str(clf_SVC.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
